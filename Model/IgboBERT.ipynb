{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IboBERT",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chiamakac/IgboNER-Models/blob/main/Model/IgboBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training an Igbo language model from scratch using Transformers and Tokenizers**"
      ],
      "metadata": {
        "id": "4eudk9KP37g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Getting the data.**"
      ],
      "metadata": {
        "id": "fuK92URk4X7f"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4amslz4Oo9vT"
      },
      "source": [
        "!wget -c https://github.com/IgnatiusEzeani/IGBONLP/raw/master/ig_monoling/text.zip\n",
        "!wget -c https://raw.githubusercontent.com/chiamaka249/lacuna_pos_ner/main/language_corpus/ibo/ibo.txt\n",
        "!wget -c https://raw.githubusercontent.com/Chiamakac/IboBETA/main/config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSkvlYoplYP"
      },
      "source": [
        "#Unzip the zipped file and remove the zipped file after unzipping\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "def unzip(zipfilename):\n",
        "  try:\n",
        "    with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(zipfilename[:-4])\n",
        "      return f\"'{zipfilename}' unzipped!\"\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Cannot find '{zipfilename}' file\")\n",
        "\n",
        "unzip(\"text.zip\")\n",
        "!rm text.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua0R2p31p8zA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2676fd77-b437-4442-8af0-be4d301d681a"
      },
      "source": [
        "#copies the file \"ibo.txt\" into the folder \"text\"\n",
        "import shutil\n",
        "shutil.move('/content/ibo.txt', '/content/text')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/text/ibo.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj4i2-9bp4U3"
      },
      "source": [
        "\n",
        "# import os\n",
        "#import shutil\n",
        "dir_name = \"/content/text\"\n",
        "text=\"\"\n",
        "for fname in os.listdir(dir_name):\n",
        "  fname = os.path.join(dir_name, fname)\n",
        "  with open(fname, \"r\", encoding=\"utf8\") as datafile:\n",
        "    text = text+\"\\n\"+datafile.read()\n",
        "\n",
        "with open(\"data.txt\", \"w\", encoding=\"utf8\") as datafile:\n",
        "  datafile.write(text)\n",
        "\n",
        "shutil.rmtree(\"text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  Import Transformers, Tokenizer and Train the tokenizer**"
      ],
      "metadata": {
        "id": "kEMNI_qD9lq3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLhNvJubEowT"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "\n",
        "# Install `transformers` from master stating the version\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'\n",
        "\n",
        "# transformers version at notebook update --- 2.11.0\n",
        "# tokenizers version at notebook update --- 0.8.0rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyraD86RE3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb67e7f7-7f52-4081-ec7c-e15f5baf742b"
      },
      "source": [
        "\n",
        "%%time \n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# Describing the path to all of our Igbo data \n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "print(paths)\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",#Beginning of sequence (BOS) or classifier (CLS) token\n",
        "    \"<pad>\",# Padding token\n",
        "    \"</s>\",#End of sequence (EOS) or seperator (SEP) token\n",
        "    \"<unk>\",# Unknown token\n",
        "    \"<mask>\", # Masking token\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data.txt']\n",
            "CPU times: user 18.9 s, sys: 1.2 s, total: 20.1 s\n",
            "Wall time: 6.07 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro52g8BqFFfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dbe9f4-3ec6-4226-a44f-85249e7b0afb"
      },
      "source": [
        "#Our tokenizer is now ready and we have two files that define our new IgboBert tokenizer( a vocab.json-which is a list of the most frequent tokens ranked by frequency and a merges.txt list of merges)\n",
        "#we then save the file for later use\n",
        "\n",
        "!mkdir IgboBert\n",
        "tokenizer.save_model(\"IgboBert\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IgboBert/vocab.json', 'IgboBert/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.move('/content/config.json', '/content/IgboBert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PtLNA80d4Olp",
        "outputId": "e60d6c56-3f90-4f59-c45e-88ed1e24b357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/IgboBert/config.json'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Initializing the Tokenizer**\n",
        "\n",
        "Let's initialize our tokenizer. This way we can use it as we would use any other from_pretrained tokenizer."
      ],
      "metadata": {
        "id": "KSuZYOW7NQP8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekvedLrFR_t"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./IgboBert/vocab.json\",\n",
        "    \"./IgboBert/merges.txt\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E52LgvLWFbuq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm7h9ndFis2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbc3757-ea78-43b6-ca12-fb30cf08fff8"
      },
      "source": [
        "tokenizer.encode(\"Simone gara ·ª•ka ·ª•nyah·ª• gu·ªç egwu ma ga-kwa taa.\", \"Aha ya b·ª• ifeoma.\").tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'Simone',\n",
              " 'ƒ†gara',\n",
              " 'ƒ†√°¬ª¬•ka',\n",
              " 'ƒ†√°¬ª¬•nyah√°¬ª¬•',\n",
              " 'ƒ†gu',\n",
              " '√°¬ªƒØ',\n",
              " 'ƒ†egwu',\n",
              " 'ƒ†ma',\n",
              " 'ƒ†ga',\n",
              " '-',\n",
              " 'kwa',\n",
              " 'ƒ†taa',\n",
              " '.',\n",
              " '</s>',\n",
              " 'Aha',\n",
              " 'ƒ†ya',\n",
              " 'ƒ†b√°¬ª¬•',\n",
              " 'ƒ†ife',\n",
              " 'oma',\n",
              " '.',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxcYhcxRKROn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe65a457-95c2-4313-8a84-779fe28916c3"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 15 20:56:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMe5vRLvG5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf36130-8252-4815-d7b5-009eb5b738e2"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtbKfFgG-Y3"
      },
      "source": [
        "#For training, we need a raw (not pre-trained) BERTLMHeadModel. \n",
        "#To create that, we first need to create a RoBERTa config object to describe the parameters we‚Äôd like to initialize IgboBERT with.\n",
        "\n",
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIqujlqjHQnX"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./IgboBert\", max_len=512, config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvup7wl8Hhp9"
      },
      "source": [
        "#We import and initialize our RoBERTa model with a language modeling (LM) head.\n",
        "\n",
        "from transformers import RobertaForMaskedLM\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWUosTlHnRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21dee24f-eda3-4536-db2f-a45ea15ee120"
      },
      "source": [
        "model.num_parameters()\n",
        "# => 83 million parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujpbn1oHp-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48e387e-4589-449b-e1d9-68c4a68243e9"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/data.txt\",\n",
        "    block_size = 128\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33.3 s, sys: 1.27 s, total: 34.5 s\n",
            "Wall time: 15.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EICtSzqwH618"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kalucrRPH9wb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./IgboBert\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCWG7CRZIOkb"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkwVjpAyIVu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df90570-f57d-489f-9329-68da775e2c90"
      },
      "source": [
        "trainer.save_model(\"./IgboBert\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./IgboBert\n",
            "Configuration saved in ./IgboBert/config.json\n",
            "Model weights saved in ./IgboBert/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Test the Model**\n",
        "\n",
        "We first initialize a pipeline object, using the 'fill-mask' argument. Then begin testing our model like so\n",
        "\n"
      ],
      "metadata": {
        "id": "RS_L5EpBYJvF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYx9FK7ZIYZs"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./IgboBert\",\n",
        "    tokenizer=\"./IgboBert\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQK6jyf9IkRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3a764f-2dae-4513-909e-1cf5edc59a1d"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ab·ª• m Maaz·ªã <mask>.\") #= okafor/·ªåkaf·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.008856686763465405,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã Mohammed.',\n",
              "  'token': 3231,\n",
              "  'token_str': ' Mohammed'},\n",
              " {'score': 0.007911812514066696,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã O.',\n",
              "  'token': 381,\n",
              "  'token_str': ' O'},\n",
              " {'score': 0.00748562254011631,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã ·ªåkaf·ªç.',\n",
              "  'token': 5307,\n",
              "  'token_str': ' ·ªåkaf·ªç'},\n",
              " {'score': 0.006802904885262251,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã A.',\n",
              "  'token': 348,\n",
              "  'token_str': ' A'},\n",
              " {'score': 0.0032701685559004545,\n",
              "  'sequence': 'Ab·ª• m Maaz·ªã Rutherford.',\n",
              "  'token': 5113,\n",
              "  'token_str': ' Rutherford'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0mje0nMIoWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd4723c-a3eb-4cc3-8c35-1bfb14cb421c"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #= eri\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1661785989999771,\n",
              "  'sequence': 'Nwaany·ªã na ya ji na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.11589646339416504,\n",
              "  'sequence': 'Nwaany·ªã na nwaany·ªã ji na akara.',\n",
              "  'token': 623,\n",
              "  'token_str': ' nwaany·ªã'},\n",
              " {'score': 0.03902192786335945,\n",
              "  'sequence': 'Nwaany·ªã na nwunye ji na akara.',\n",
              "  'token': 724,\n",
              "  'token_str': ' nwunye'},\n",
              " {'score': 0.038711633533239365,\n",
              "  'sequence': 'Nwaany·ªã na nna ji na akara.',\n",
              "  'token': 713,\n",
              "  'token_str': ' nna'},\n",
              " {'score': 0.02920209988951683,\n",
              "  'sequence': 'Nwaany·ªã na- ji na akara.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9wjE8PItpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1aed77-ff16-4e7f-c001-888d53f984b5"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Chineke ga- ebibikwa nd·ªã niile na- eme ihe <mask>.\") #=·ªçj·ªç·ªç\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.24352985620498657,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçma.',\n",
              "  'token': 496,\n",
              "  'token_str': ' ·ªçma'},\n",
              " {'score': 0.16800811886787415,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe ·ªçj·ªç·ªç.',\n",
              "  'token': 707,\n",
              "  'token_str': ' ·ªçj·ªç·ªç'},\n",
              " {'score': 0.15601330995559692,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe a.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.11959126591682434,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe niile.',\n",
              "  'token': 427,\n",
              "  'token_str': ' niile'},\n",
              " {'score': 0.02550322934985161,\n",
              "  'sequence': 'Chineke ga- ebibikwa nd·ªã niile na- eme ihe oriri.',\n",
              "  'token': 1580,\n",
              "  'token_str': ' oriri'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubR7pCxJIyNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a99ff7-904b-4551-dbd1-925c53b39399"
      },
      "source": [
        "fill_mask(\"·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã <mask>.\") #n'Awka\n",
        "\n",
        "# This is the beginning of a beautiful <mask>.\n",
        "# =>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10755623877048492,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã mkpa.',\n",
              "  'token': 607,\n",
              "  'token_str': ' mkpa'},\n",
              " {'score': 0.07236427068710327,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã nso.',\n",
              "  'token': 604,\n",
              "  'token_str': ' nso'},\n",
              " {'score': 0.067164845764637,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã mma.',\n",
              "  'token': 347,\n",
              "  'token_str': ' mma'},\n",
              " {'score': 0.054604168981313705,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã iche.',\n",
              "  'token': 462,\n",
              "  'token_str': ' iche'},\n",
              " {'score': 0.04094060882925987,\n",
              "  'sequence': '·ªçba akw·ª•kw·ªç ·ªåkamm·ª•ta Kenneth Dike d·ªã ukwuu.',\n",
              "  'token': 1009,\n",
              "  'token_str': ' ukwuu'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgveMBQYNZV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c0ff50-c1ef-4a27-88ee-1148af67f588"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwaany·ªã na eri <mask> na akara.\") #= ji\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.12033308297395706,\n",
              "  'sequence': 'Nwaany·ªã na eri ya na akara.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.07522733509540558,\n",
              "  'sequence': 'Nwaany·ªã na eri nri na akara.',\n",
              "  'token': 870,\n",
              "  'token_str': ' nri'},\n",
              " {'score': 0.0471433624625206,\n",
              "  'sequence': 'Nwaany·ªã na eri ihe na akara.',\n",
              "  'token': 300,\n",
              "  'token_str': ' ihe'},\n",
              " {'score': 0.02259232848882675,\n",
              "  'sequence': 'Nwaany·ªã na eri eri na akara.',\n",
              "  'token': 957,\n",
              "  'token_str': ' eri'},\n",
              " {'score': 0.01788548193871975,\n",
              "  'sequence': 'Nwaany·ªã na eri nwaany·ªã na akara.',\n",
              "  'token': 623,\n",
              "  'token_str': ' nwaany·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Gaan·ª• mee nd·ªã <mask> niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m  .\") #= mba\n"
      ],
      "metadata": {
        "id": "-JgRzOtZmTtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38fc22c-dcb1-43f8-b98c-6de4a997886d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3522748351097107,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã a niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.08272776752710342,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã ·ªçz·ªç niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 434,\n",
              "  'token_str': ' ·ªçz·ªç'},\n",
              " {'score': 0.06121758744120598,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã ah·ª• niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 310,\n",
              "  'token_str': ' ah·ª•'},\n",
              " {'score': 0.06120830774307251,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã mmad·ª• niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.04012814536690712,\n",
              "  'sequence': 'Gaan·ª• mee nd·ªã Izrel niile ka ha b·ª•r·ª• nd·ªã na- eso ·ª•z·ªç m .',\n",
              "  'token': 680,\n",
              "  'token_str': ' Izrel'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• <mask>.\") #= Izrel\n"
      ],
      "metadata": {
        "id": "_zB0aW-cmuQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103711b5-3d4d-4408-b27b-f543735aeb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3820941150188446,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• Izrel.',\n",
              "  'token': 680,\n",
              "  'token_str': ' Izrel'},\n",
              " {'score': 0.2837800979614258,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ya.',\n",
              "  'token': 289,\n",
              "  'token_str': ' ya'},\n",
              " {'score': 0.10724257677793503,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• mmad·ª•.',\n",
              "  'token': 393,\n",
              "  'token_str': ' mmad·ª•'},\n",
              " {'score': 0.024513551965355873,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• ha.',\n",
              "  'token': 296,\n",
              "  'token_str': ' ha'},\n",
              " {'score': 0.01360291987657547,\n",
              "  'sequence': 'Jehova h·ªçp·ª•tara Mozis ka ·ªç b·ª•r·ª• onye nd√∫ ·ª•m·ª• Igbo.',\n",
              "  'token': 900,\n",
              "  'token_str': ' Igbo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka <mask> Haram.\") #= Boko\n"
      ],
      "metadata": {
        "id": "BD8wh6YRmtbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77835576-ece5-43c9-aa0d-100fe95077f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8887956738471985,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Boko Haram.',\n",
              "  'token': 2535,\n",
              "  'token_str': ' Boko'},\n",
              " {'score': 0.007407982833683491,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Manchester Haram.',\n",
              "  'token': 3278,\n",
              "  'token_str': ' Manchester'},\n",
              " {'score': 0.007324530277401209,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka Super Haram.',\n",
              "  'token': 3199,\n",
              "  'token_str': ' Super'},\n",
              " {'score': 0.0033930952195078135,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka ·ªãgba Haram.',\n",
              "  'token': 874,\n",
              "  'token_str': ' ·ªãgba'},\n",
              " {'score': 0.0025665571447461843,\n",
              "  'sequence': '·ª§m·ª•akw·ª•kw·ªç Chibok an·ªç·ªçla ·ª•b·ªçch·ªã 2000 n‚Äô aka G·ªçvan·ªç Haram.',\n",
              "  'token': 1692,\n",
              "  'token_str': ' G·ªçvan·ªç'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado <mask> ·ªçh·ª•r·ª• a.\") #= iwu\n"
      ],
      "metadata": {
        "id": "k6sdE6Wemswq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8d7c9b-2f39-4e3d-d5a2-7c919001a35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1165534108877182,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçch·ªãch·ªã ·ªçh·ª•r·ª• a.',\n",
              "  'token': 719,\n",
              "  'token_str': ' ·ªçch·ªãch·ªã'},\n",
              " {'score': 0.056705061346292496,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçr·ª• ·ªçh·ª•r·ª• a.',\n",
              "  'token': 477,\n",
              "  'token_str': ' ·ªçr·ª•'},\n",
              " {'score': 0.04727887734770775,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ªçn·ªçd·ª• ·ªçh·ª•r·ª• a.',\n",
              "  'token': 1036,\n",
              "  'token_str': ' ·ªçn·ªçd·ª•'},\n",
              " {'score': 0.042590655386447906,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado ·ª•wa ·ªçh·ª•r·ª• a.',\n",
              "  'token': 556,\n",
              "  'token_str': ' ·ª•wa'},\n",
              " {'score': 0.0251015517860651,\n",
              "  'sequence': 'Nwunye G·ªçvan·ªç Ekiti steeti b·ª• Bisi Fayemi so na nd·ªã na- akwado obodo ·ªçh·ª•r·ª• a.',\n",
              "  'token': 576,\n",
              "  'token_str': ' obodo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\" <mask> s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.\") #= Buhari\n"
      ],
      "metadata": {
        "id": "X8e7jRBLmrtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3219736a-eee0-46a7-fc32-ea3cf88fad13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.44573667645454407,\n",
              "  'sequence': 'A s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 37,\n",
              "  'token_str': 'A'},\n",
              " {'score': 0.230531707406044,\n",
              "  'sequence': '·ªå s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 336,\n",
              "  'token_str': '·ªå'},\n",
              " {'score': 0.03158653527498245,\n",
              "  'sequence': 'Ha s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 513,\n",
              "  'token_str': 'Ha'},\n",
              " {'score': 0.02112211100757122,\n",
              "  'sequence': 'Igbo s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 3656,\n",
              "  'token_str': 'Igbo'},\n",
              " {'score': 0.011359370313584805,\n",
              "  'sequence': 'O s·ªã ka ehiwe ·ª•l·ªçikpe p·ª•r·ª•iche maka mp·ª•.',\n",
              "  'token': 51,\n",
              "  'token_str': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"Ala <mask>  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.\") #= Na·ªãjir·ªãa\n"
      ],
      "metadata": {
        "id": "b1uSDAbWmq3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4104903e-6503-4b8f-fe99-a5c0dfc6852b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.10420944541692734,\n",
              "  'sequence': 'Ala a  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 266,\n",
              "  'token_str': ' a'},\n",
              " {'score': 0.07349573075771332,\n",
              "  'sequence': 'Ala ah·ª•  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 310,\n",
              "  'token_str': ' ah·ª•'},\n",
              " {'score': 0.030463453382253647,\n",
              "  'sequence': 'Ala Igbo  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 900,\n",
              "  'token_str': ' Igbo'},\n",
              " {'score': 0.02490180917084217,\n",
              "  'sequence': 'Ala Nigeria  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 1570,\n",
              "  'token_str': ' Nigeria'},\n",
              " {'score': 0.01187092810869217,\n",
              "  'sequence': 'Ala ·ªçr·ª•  ga- eweta ezi ·ªçn·ªçd·ª• nchekwa maka nd·ªã ch·ªçr·ªç ·ªãwebata ego n‚Äô ·ªçr·ª• ugbo.',\n",
              "  'token': 477,\n",
              "  'token_str': ' ·ªçr·ª•'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbvsFIyNpID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31991bc9-6577-483d-d9bc-f0d68373fb44"
      },
      "source": [
        "# The sun <mask>.\n",
        "# =>\n",
        "\n",
        "fill_mask(\"·ªå b·ª• <mask>a ka a na- ar·ªãa .\") #= mmad·ª•\n",
        "# fill_mask(\"Nwaany·ªã na <mask> ji na akara.\") #=eri"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.044008973985910416,\n",
              "  'sequence': '·ªå b·ª•-a ka a na- ar·ªãa.',\n",
              "  'token': 17,\n",
              "  'token_str': '-'},\n",
              " {'score': 0.0439983569085598,\n",
              "  'sequence': '·ªå b·ª• nwaa ka a na- ar·ªãa.',\n",
              "  'token': 419,\n",
              "  'token_str': ' nwa'},\n",
              " {'score': 0.041657522320747375,\n",
              "  'sequence': '·ªå b·ª• Nwannaa ka a na- ar·ªãa.',\n",
              "  'token': 1459,\n",
              "  'token_str': ' Nwanna'},\n",
              " {'score': 0.018149062991142273,\n",
              "  'sequence': '·ªå b·ª• ·ªçr·ªãaa ka a na- ar·ªãa.',\n",
              "  'token': 956,\n",
              "  'token_str': ' ·ªçr·ªãa'},\n",
              " {'score': 0.009843925014138222,\n",
              "  'sequence': '·ªå b·ª• naan·ªãa ka a na- ar·ªãa.',\n",
              "  'token': 769,\n",
              "  'token_str': ' naan·ªã'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Hddc-BufgXzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903e12a9-703c-42e5-d7b0-45e98b4f9844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#move model to gdrive\n",
        "shutil.move('model path','drive path')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GvyCrVFLwlLZ",
        "outputId": "1ce40fa6-2616-44b5-e0c8-bdf5cd5ecb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/IBO_BETA/IgboBert'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}